{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 24 18:58:15 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.09                 Driver Version: 546.09       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce MX230         WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   74C    P0              N/A / ERR! |      0MiB /  2048MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "\n",
    "model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "persist_directory = './app/storage/db/'\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='langchain' id=UUID('8b73c01e-4beb-47a5-b3e2-36d13a310fa1') metadata=None tenant='default_tenant' database='default_database'\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "langchain = vectordb._collection\n",
    "print(langchain.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Gorilla: Large Language Model Connected with\\nMassive APIs\\nShishir G. Patil1∗Tianjun Zhang1,∗Xin Wang2Joseph E. Gonzalez1\\n1UC Berkeley2Microsoft Research\\nsgp@berkeley.edu\\nAbstract\\nLarge Language Models (LLMs) have seen an impressive wave of advances re-\\ncently, with models now excelling in a variety of tasks, such as mathematical\\nreasoning and program synthesis. However, their potential to effectively use tools\\nvia API calls remains unfulfilled. This is a challenging task even for today’s state-of-\\nthe-art LLMs such as GPT-4, largely due to their inability to generate accurate input\\narguments and their tendency to hallucinate the wrong usage of an API call. We\\nrelease Gorilla, a finetuned LLaMA-based model that surpasses the performance\\nof GPT-4 on writing API calls. When combined with a document retriever, Gorilla\\ndemonstrates a strong capability to adapt to test-time document changes, enabling\\nflexible user updates or version changes. It also substantially mitigates the issue of\\nhallucination, commonly encountered when prompting LLMs directly. To evaluate\\nthe model’s ability, we introduce APIBench, a comprehensive dataset consisting\\nof HuggingFace, TorchHub, and TensorHub APIs. The successful integration of\\nthe retrieval system with Gorilla demonstrates the potential for LLMs to use tools\\nmore accurately, keep up with frequently updated documentation, and consequently\\nincrease the reliability and applicability of their outputs. Gorilla’s code, model,\\ndata, and demo are available at https://gorilla.cs.berkeley.edu\\n1 Introduction\\nRecent advances in large language models (LLMs) [ 10,5,32,6,29,30] have enabled significant new\\ncapabilities including natural dialogue, mathematical reasoning, and program synthesis. However,\\ndespite these advances, LLMs are still fundamentally limited by the information they can store in a\\nfixed set of weights and the things they can compute using a static computation graph and limited\\ncontext. Furthermore, as the world changes, LLMs require retraining to update their knowledge and\\nreasoning capabilities.\\nBy empowering LLMs to use tools [ 33], we can grant access to vastly larger and changing knowledge\\nbases and accomplish complex computational tasks. By providing access to search technologies and\\ndatabases, [ 26,39,37] demonstrated that we can augment LLMs to address a significantly larger\\nand more dynamic knowledge space. Similarly, by providing access to computational tools, [ 39,2]\\ndemonstrated that LLMs can accomplish complex computational tasks. Consequently, leading LLM\\nproviders[ 29], have started to integrate plugins to allow LLMs to invoke external tools through APIs.\\nThis transition from a small set of hand-coded tools, to the ability to invoke a vast space of changing\\ncloud APIs could transform LLMs into the primary interface to computing infrastructure and the web.\\nTasks ranging from booking an entire vacation to hosting a conference, could become as simple as\\ntalking to an LLM that has access to the flight, car rental, hotel, catering, and entertainment web\\nAPIs. However, much of the prior work [ 35,24] integrating tools into LLMs considered a small well\\ndocumented set of APIs that can be easily injected into the prompt.\\n∗Equal contribution.\\nPreprint. Under review.arXiv:2305.15334v1  [cs.CL]  24 May 2023', metadata={'page': 0, 'source': 'C:\\\\Users\\\\Dinakar\\\\Documents\\\\GenerativeAI\\\\rag-enterprises\\\\rag-langchain\\\\backend\\\\app/storage/data\\\\Gorilla.pdf'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = \"What is Gorilla?\"\n",
    "\n",
    "vectordb.similarity_search(q1, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "doc_1 =  Document(\n",
    "    page_content=\"Wareconn is the best web platform for warranty maintenance.\",\n",
    "    metadata={\n",
    "        \"source\": \"wareconn.com\",\n",
    "        \"page\": 1\n",
    "    }\n",
    ")\n",
    "\n",
    "doc_2 = Document(\n",
    "    page_content=\"It is easy to navigate to the RMA request page in the Wareconn Customer Portal.\",\n",
    "    metadata={\n",
    "        \"source\": \"wareconn.com\",\n",
    "        \"page\": 2\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docs = [doc_1, doc_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = PyPDFLoader(r\"C:\\Users\\Dinakar\\Documents\\GenerativeAI\\rag-enterprises\\rag-langchain\\backend\\app\\storage\\data\\Gorilla.pdf\")\n",
    "raw_document = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "separator=\"\\n\\n\",\n",
    "chunk_size=800,\n",
    "chunk_overlap=100,\n",
    "length_function=len,\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(raw_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = vectordb.add_documents(\n",
    "    new_docs,\n",
    "    ids=[\"wareconn_1\", \"wareconn_2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15fa3181-d043-49a7-8f88-f13d8d84258b',\n",
       " '0a03e8da-2843-4986-bbaf-fbef578f3339',\n",
       " '54442d67-2118-445c-9f9f-ba86239345aa',\n",
       " 'f12c04e6-0243-4506-92be-3a5782063ea9',\n",
       " 'f5ada0cc-c293-4929-925b-bf49ee01ee4f',\n",
       " 'c6f89efa-fce9-404c-bc72-1836989e09a3',\n",
       " '067b3fed-3679-45f9-a1ad-c89201d8589e',\n",
       " '83916e76-618e-4796-a47b-f4b14e7b5f42',\n",
       " 'addf93a1-6cad-4c95-8ee8-d0481b39bfd3',\n",
       " 'a2d0c70e-4e22-471a-a042-2e7e02a3badc',\n",
       " 'd4d22b2b-83bd-4f20-a97b-d78f65075b89',\n",
       " '585cd1d0-748b-4671-bdea-3b49a1afeee2',\n",
       " 'a982419a-5271-4967-bf1b-6ffc56d072c5',\n",
       " 'f4a5eeba-e24b-487a-9659-0224d3860c55',\n",
       " '042ada6d-c928-49c0-bdaa-cfcb3619f2bd',\n",
       " '4785bbcb-70cd-4e4e-9bda-5884192accc8',\n",
       " 'c699e98f-7fa5-489f-bb49-98efa5ea09d3',\n",
       " '295a5a50-4b6b-4c63-b98f-ddf4410ebfb5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.add_documents(documents) # if ids are not provided, they will be generated automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Wareconn is the best web platform for warranty maintenance.', metadata={'page': 1, 'source': 'wareconn.com'}),\n",
       " Document(page_content='It is easy to navigate to the RMA request page in the Wareconn Customer Portal.', metadata={'page': 2, 'source': 'wareconn.com'})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.similarity_search(\"What is the best web platform for warranty maintenance?\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update a Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_doc =  Document(\n",
    "    page_content=\"Wareconn is the perfect web platform for warranty maintenance.\",\n",
    "    metadata={\n",
    "        \"source\": \"wareconn.com\",\n",
    "        \"page\": 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7']\n",
      "{'ids': ['7'], 'embeddings': None, 'metadatas': [{'page': 1, 'source': 'wareconn.com'}], 'documents': ['Wareconn is the best web platform for warranty maintenance.'], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "print(id)\n",
    "\n",
    "print(vectordb._collection.get(ids=id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.update_document(id[0], update_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['7'], 'embeddings': None, 'metadatas': [{'page': 1, 'source': 'wareconn.com'}], 'documents': ['Wareconn is the perfect web platform for warranty maintenance.'], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.get(ids=id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='langchain' id=UUID('8b73c01e-4beb-47a5-b3e2-36d13a310fa1') metadata=None tenant='default_tenant' database='default_database'\n",
      "No. of documents in the collection: 64\n"
     ]
    }
   ],
   "source": [
    "collection = vectordb._collection\n",
    "\n",
    "print(collection)\n",
    "print(f\"No. of documents in the collection: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: 1a48c600-36c3-494c-a4de-da5e8510518a\n",
      "Delete of nonexisting embedding ID: 1e59bcee-ac53-4bb8-8fbd-ac98d7b68738\n",
      "Delete of nonexisting embedding ID: 28615cdc-4140-4aad-a24c-3509fa4a6632\n",
      "Delete of nonexisting embedding ID: 293749da-381f-4dc8-8683-7944312e98b8\n",
      "Delete of nonexisting embedding ID: 2db57753-8eed-4279-a1f1-c10640dc2c76\n",
      "Delete of nonexisting embedding ID: 2fb34812-d859-416a-850c-3c3485513ccd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: 44212ef9-5250-49de-b3dc-28d35a5dc256\n",
      "Delete of nonexisting embedding ID: 4550dcb2-519d-4b28-890b-196a632d39dd\n",
      "Delete of nonexisting embedding ID: 4c55194c-ab5a-4ebf-8285-1fbc5baab20b\n",
      "Delete of nonexisting embedding ID: 6c1c1553-86da-44d6-a2d6-c7967b8e04d7\n",
      "Delete of nonexisting embedding ID: 6e7c934a-870e-4478-b3c3-c31fd28abd1a\n",
      "Delete of nonexisting embedding ID: 7bc0b60d-dbc4-4d7b-bb88-253821d6a163\n",
      "Delete of nonexisting embedding ID: 88e5325b-d57a-4a59-a096-fa48f7f2fdbc\n",
      "Delete of nonexisting embedding ID: 8dad088f-6a94-4f5b-a1ef-262c94e3b26d\n",
      "Delete of nonexisting embedding ID: b0c468c5-f747-4a3a-8da2-5ef2eb1a5dd1\n",
      "Delete of nonexisting embedding ID: b2337f4e-d3f0-4ed3-bf99-473e4d95b735\n",
      "Delete of nonexisting embedding ID: d487ad73-74c8-422d-9d77-b5cd496cd54b\n",
      "Delete of nonexisting embedding ID: ec6e3483-bd35-4372-bef8-7e303720922f\n"
     ]
    }
   ],
   "source": [
    "# Get all the document ids in the collection\n",
    "# print(collection.get()) # # dict_keys(['ids', 'embeddings', 'documents', 'metadatas'])\n",
    "\n",
    "# Filter the documents whose metadata contains the key 'source' that includes the string 'Gorilla'\n",
    "\n",
    "# print(collection.filter_metadata(\"source\", \"Gorilla.pdf\"))\n",
    "\n",
    "coll = collection.get()\n",
    "\n",
    "ids_to_delete = []\n",
    "\n",
    "for idx in range(len(coll['ids'])):\n",
    "\n",
    "    id = coll['ids'][idx]\n",
    "    metadata = coll['metadatas'][idx]\n",
    "\n",
    "    if 'Gorilla.pdf' in metadata['source']:\n",
    "        ids_to_delete.append(id)\n",
    "        \n",
    "vectordb._collection.delete(ids_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "print(collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"What's \\nunique\\n•AI-driven feedback and \\nimprovement suggestions\\n•Wide range of practice modes \\ntailored to different communication \\nscenarios\\n•Engaging Community Chat for \\ncollaborative learning and resource \\nsharing\\n•Speech -to-text analysis for \\nimmediate feedback\\n•Integration of famous quotes and \\nexcerpts for enriched learning \\nexperience\", metadata={'page': 7, 'source': 'C:\\\\Users\\\\Dinakar\\\\Documents\\\\GenerativeAI\\\\rag-enterprises\\\\rag-langchain\\\\backend\\\\app/storage/data\\\\Final Year Project Presentation.pdf'}),\n",
       " Document(page_content=\"Problems we're trying to solve\\nMASTERING CHATGPT (OR \\nSIMILAR LLMS) INTERACTIONS \\nLEADS TO MORE EFFECTIVE \\nCOMMUNICATION AND \\nBETTER RESULTS FROM THE AI.\\nDESCRIPTIVE WRITING SKILLS \\nENHANCE MIDJOURNEY -\\nGENERATED IMAGE -TO-TEXT \\nRESULTS, BOOSTING \\nCREATIVITY AND ACCURACY.\\nCONFIDENT AND ENGAGING \\nPRESENTATIONS ARE \\nESSENTIAL FOR CONVEYING \\nIDEAS AND SECURING \\nSUPPORT.\\nEFFECTIVE STORYTELLING \\nSKILLS HELP PITCH IDEAS \\nSUCCESSFULLY, CAPTURING \\nTHE INTEREST OF INVESTORS \\nOR COMPANIONS.\\nQUICK -WITTED THINKING AND \\nELOQUENCE EMPOWER \\nINDIVIDUALS TO DELIVER \\nIMPRESSIVE SPEECHES, EVEN \\nUNDER PRESSURE OR TIGHT \\nDEADLINES.\", metadata={'page': 5, 'source': 'C:\\\\Users\\\\Dinakar\\\\Documents\\\\GenerativeAI\\\\rag-enterprises\\\\rag-langchain\\\\backend\\\\app/storage/data\\\\Final Year Project Presentation.pdf'})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.similarity_search(\"What is Gorilla?\", k=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
